{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ChestdataCNN.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bkJRKlBo0afB","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwykZiTZ1YVS","colab_type":"code","outputId":"c13ba337-2104-49ea-a83a-92a38171ef4a","executionInfo":{"status":"ok","timestamp":1572881979884,"user_tz":480,"elapsed":418,"user":{"displayName":"Haripriya Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCmxvYbUXg0huvbQ0TKNZ-raB8DNt-OrsgAOfbI=s64","userId":"14567850624853281187"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ot4jNnjt1oz6","colab_type":"code","colab":{}},"source":["def get_chest_images():\n","\n","  TRANSFORM_IMG = transforms.Compose([\n","          transforms.Resize((256, 256)),\n","          transforms.ToTensor(),\n","          ])\n","\n","  file_path = \"/content/drive/My Drive/6.867 project/data/\"\n","\n","\n","\n"," trainset = datasets.ImageFolder(root=file_path+\"train\", transform=TRANSFORM_IMG)\n","  trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n","                                            shuffle=True, num_workers=2)\n","\n","  valset = datasets.ImageFolder(root= file_path+\"test\", transform=TRANSFORM_IMG)\n","  valloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                          shuffle=False, num_workers=2)\n","  \n","\n","\n","  return trainloader, valloader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvCTT_5Q0fnw","colab_type":"code","colab":{}},"source":["class Chest_Disease_Net(nn.Module):\n","    def __init__(self):\n","        super(Chest_Disease_Net, self).__init__()\n","        \n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=16, stride=3, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=5, stride=2)\n","        )\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=7, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=5, stride=2)\n","        )\n","\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU()\n","        )\n","        \n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU()\n","        )\n","\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","\n","        self.fc1 = nn.Sequential(\n","            nn.Linear(12544, 512),\n","            nn.ReLU(),\n","        )\n","        self.fc2 = nn.Sequential(\n","            nn.Linear(512, 512),\n","            nn.ReLU()\n","        )\n","        self.fc3 = nn.Linear(512,2)\n","         \n","    def forward(self, x):\n","        print(x.shape)\n","        out = self.layer1(x)\n","        print(out.shape)\n","        out = self.layer2(out)\n","        print(out.shape)\n","        out = self.layer3(out)\n","        print(out.shape)\n","        out = self.layer4(out)\n","        print(out.shape)\n","        out = self.layer5(out)\n","        print(out.shape)\n","        out = out.reshape(out.size(0), -1)\n","        print(out.shape)\n","        out = self.fc1(out)\n","        print(out.shape)\n","        out = self.fc2(out)\n","        print(out.shape)\n","        out = self.fc3(out)\n","        print(out.shape)\n","        return(out)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeXenRjt-uPE","colab_type":"code","outputId":"1b52cd6a-a4a2-4524-a769-84357eb448c8","executionInfo":{"status":"error","timestamp":1572887385502,"user_tz":480,"elapsed":41387,"user":{"displayName":"Haripriya Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCmxvYbUXg0huvbQ0TKNZ-raB8DNt-OrsgAOfbI=s64","userId":"14567850624853281187"}},"colab":{"base_uri":"https://localhost:8080/","height":990}},"source":["def run():\n","    # Parameters\n","    num_epochs = 10\n","    output_period = 100\n","    batch_size = 100\n","\n","    # setup the device for running\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model = Chest_Disease_Net()\n","    model = model.to(device)\n","\n","    train_loader, val_loader = get_chest_images()\n","    num_train_batches = len(train_loader)\n","\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","    epoch = 1\n","    while epoch <= num_epochs:\n","        running_loss = 0.0\n","        for param_group in optimizer.param_groups:\n","            print('Current learning rate: ' + str(param_group['lr']))\n","        model.train()\n","\n","        for batch_num, (inputs, labels) in enumerate(tqdm(train_loader), 1):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","            if batch_num % output_period == 0:\n","                '''\n","                print('[%d:%.2f] loss: %.3f' % (\n","                    epoch, batch_num*1.0/num_train_batches,\n","                    running_loss/output_period\n","                    ))\n","                '''\n","                running_loss = 0.0\n","                gc.collect()\n","\n","        gc.collect()\n","        # save after every epoch\n","        torch.save(model.state_dict(), \"models/model.%d\" % epoch)\n","\n","\n","        val_correct = 0\n","        correct = 0\n","        val_total = 0\n","        with torch.no_grad():\n","            for data in tqdm(val_loader):\n","                images, labels = data\n","                images = images.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                _, predicted_five = torch.topk(outputs.data, 5, dim=1)\n","\n","                val_total += labels.size(0)\n","\n","                correct += (predicted == labels).sum().item()\n","                val_correct += (predicted_five[:, 0] == labels).sum().item()\n","                val_correct += (predicted_five[:, 1] == labels).sum().item()\n","                val_correct += (predicted_five[:, 2] == labels).sum().item()\n","                val_correct += (predicted_five[:, 3] == labels).sum().item()\n","                val_correct += (predicted_five[:, 4] == labels).sum().item()\n","        print('Top One Error of the network on validation images: %d %%' % (\n","           100 * (1 - correct/val_total)))\n","        print('Top Five Error of the network on validation images: %d %%' % (\n","           100 * (1 - val_correct / val_total)))\n","\n","        gc.collect()\n","        epoch += 1\n","\n","run()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["\n","\n","  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Current learning rate: 0.001\n","torch.Size([128, 1, 256, 256])\n","torch.Size([128, 64, 39, 39])\n","torch.Size([128, 128, 15, 15])\n","torch.Size([128, 256, 15, 15])\n","torch.Size([128, 256, 15, 15])\n","torch.Size([128, 256, 7, 7])\n","torch.Size([128, 12544])\n","torch.Size([128, 512])\n","torch.Size([128, 512])\n","torch.Size([128, 10])\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  0%|          | 1/469 [00:14<1:50:50, 14.21s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([128, 1, 256, 256])\n","torch.Size([128, 64, 39, 39])\n","torch.Size([128, 128, 15, 15])\n","torch.Size([128, 256, 15, 15])\n","torch.Size([128, 256, 15, 15])\n","torch.Size([128, 256, 7, 7])\n","torch.Size([128, 12544])\n","torch.Size([128, 512])\n","torch.Size([128, 512])\n","torch.Size([128, 10])\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","  0%|          | 2/469 [00:27<1:48:25, 13.93s/it]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([128, 1, 256, 256])\n","torch.Size([128, 64, 39, 39])\n","torch.Size([128, 128, 15, 15])\n","torch.Size([128, 256, 15, 15])\n","torch.Size([128, 256, 15, 15])\n","torch.Size([128, 256, 7, 7])\n","torch.Size([128, 12544])\n","torch.Size([128, 512])\n","torch.Size([128, 512])\n","torch.Size([128, 10])\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-6f0bf193099f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-31-6f0bf193099f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}