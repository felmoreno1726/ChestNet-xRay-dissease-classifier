{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.2.0\n",
      "Torchvision Version:  0.4.0a0+6b959ee\n",
      "Using GPU!\n"
     ]
    }
   ],
   "source": [
    "import custom_models\n",
    "#python packages\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm\n",
    "import gc\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage import io\n",
    "#torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "#torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU!\")\n",
    "else:\n",
    "    print(\"WARNING: Could not find GPU! Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_CNN(model_name, num_classes, resume_from = None):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    # The model (nn.Module) to return\n",
    "    model_ft = None\n",
    "    # The input image is expected to be (input_size, input_size)\n",
    "    input_size = 0\n",
    "    \n",
    "    # You may NOT use pretrained models!! \n",
    "    use_pretrained = True\n",
    "    \n",
    "    # By default, all parameters will be trained (useful when you're starting from scratch)\n",
    "    # Within this function you can set .requires_grad = False for various parameters, if you\n",
    "    # don't want to learn them\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg13\":\n",
    "        \"\"\" VGG13_bn\n",
    "        \"\"\"\n",
    "        model_ft = custom_models.vgg13_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg16\":\n",
    "        \"\"\" VGG16_bn\n",
    "        \"\"\"\n",
    "        model_ft = custom_models.vgg13_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"vgg19\":\n",
    "        \"\"\" VGG19_bn\n",
    "        \"\"\"\n",
    "        model_ft = custom_models.vgg13_bn(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Invalid model name!\")\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chest_Disease_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    fc1: number of neurons in the hidden fully connected layer\n",
    "    \"\"\"\n",
    "    def __init__(self, cnn_model_name, num_classes, num_multimodal_features=12, fc1_out=32, resume_from=None):\n",
    "        #num_classes = 14\n",
    "        #num_multimodal_features= 12\n",
    "        super(Chest_Disease_Net, self).__init__()\n",
    "        self.cnn, self.input_size = make_CNN(cnn_model_name, num_classes)#models.vgg11(pretrained=False, progress = True)\n",
    "        #define output layers\n",
    "        self.fc1 = nn.Linear(num_classes + num_multimodal_features, fc1_out) #takes in input of CNN and multimodal input\n",
    "        self.fc2 = nn.Linear(fc1_out, num_classes)\n",
    "        if resume_from is not None:\n",
    "            print(\"Loading weights from %s\" % resume_from)\n",
    "            self.load_state_dict(torch.load(resume_from))\n",
    "        \n",
    "    def forward(self, image, data):\n",
    "        x1 = self.cnn(image)\n",
    "        #print(\"x1\", x1.shape)\n",
    "        x2 = data\n",
    "        #print(\"x2\", x2.shape)\n",
    "        #print(\"x1: \", x1, type(x1))\n",
    "        #print(\"x2: \", x2, type(x2))\n",
    "        #x = torch.cat((x1, x2), dim=1)  \n",
    "        x = torch.cat((x1.float(), x2.float()), dim=1) ### ???\n",
    "        #print(\"concat\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"relu\", x.shape)\n",
    "        x = self.fc2(x)\n",
    "       # print('forward output: ', x)\n",
    "       # print(\"fc2\", x.shape)\n",
    "        return x.double() ### ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset definition\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, img_path, transform=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.diseases = self.get_diseases()\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        img_name = self.df.iloc[index][\"img_name\"] \n",
    "        img_path = os.path.join(self.img_path, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        image = np.asarray(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor # ???\n",
    "        features = np.fromstring(self.df.iloc[index][\"feature\"][1:-1], sep=\",\") # ???\n",
    "        features = torch.from_numpy(features.astype(\"float\")) # ???\n",
    "        #label = int(self.df.iloc[index]['label'])\n",
    "        labels = torch.tensor(list(self.df.iloc[index][self.diseases]), dtype = torch.float64)\n",
    "        #print(\"Label type: \", type(label))\n",
    "        #label = np.int_(label) #???\n",
    "        #print(\"label type post casting: \", type(label))\n",
    "        return image, features, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get_diseases(self):\n",
    "        cols = list(self.df.columns)\n",
    "        cols.remove('disease')\n",
    "        cols.remove('feature')\n",
    "        cols.remove('img_name')\n",
    "        cols.remove('dataset_type')\n",
    "        return cols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(input_size, batch_size, num_classes, augment=False, shuffle = True):\n",
    "    # How to transform the image when you are loading them.\n",
    "    # you'll likely want to mess with the transforms on the training set.\n",
    "    \n",
    "    # For now, we resize/crop the image to the correct input size for our network,\n",
    "    # then convert it to a [C,H,W] tensor, then normalize it to values with a given mean/stdev. These normalization constants\n",
    "    # are derived from aggregating lots of data and happen to produce better results.\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            #Add extra transformations for data augmentation\n",
    "            transforms.RandomApply([\n",
    "                transforms.RandomChoice([\n",
    "                    transforms.RandomAffine(degrees=20),\n",
    "                    transforms.RandomAffine(degrees=0,scale=(0.1, 0.15)),\n",
    "                    transforms.RandomAffine(degrees=0,translate=(0.2,0.2)),\n",
    "                    #transforms.RandomAffine(degrees=0,shear=0.15),\n",
    "                    transforms.RandomHorizontalFlip(p=1.0)\n",
    "                ] if augment else [transforms.RandomAffine(degrees=0)])#else do nothing\n",
    "            ], p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.225])\n",
    "        ])\n",
    "    }\n",
    "    # Create training and validation datasets\n",
    "    data_subsets = {x: MultimodalDataset(csv_path=\"./data/\"+x+\"_dataset{}.csv\".format(num_classes), \n",
    "                                         img_path=\"/storage/images\", \n",
    "                                         transform=data_transforms[x]) for x in data_transforms.keys()}\n",
    "    # Create training and validation dataloaders\n",
    "    # Never shuffle the test set\n",
    "    dataloaders_dict = {x: DataLoader(data_subsets[x], batch_size=batch_size, shuffle=False if x != 'train' else shuffle, num_workers=4) for x in data_transforms.keys()}\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, model_name=str(datetime.datetime.now()), \n",
    "                save_dir = None, save_all_epochs=False, num_epochs=25):\n",
    "    '''\n",
    "    model: The NN to train\n",
    "    dataloaders: A dictionary containing at least the keys \n",
    "                 'train','val' that maps to Pytorch data loaders for the dataset\n",
    "    criterion: The Loss function\n",
    "    optimizer: The algorithm to update weights \n",
    "               (Variations on gradient descent)\n",
    "    num_epochs: How many epochs to train for\n",
    "    save_dir: Where to save the best model weights that are found, \n",
    "              as they are found. Will save to save_dir/weights_best.pt\n",
    "              Using None will not write anything to disk\n",
    "    save_all_epochs: Whether to save weights for ALL epochs, not just the best\n",
    "                     validation error epoch. Will save to save_dir/weights_e{#}.pt\n",
    "    '''\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # TQDM has nice progress bars\n",
    "            for inputs, features, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs, features)\n",
    "                    #print(\"model outputs: \", outputs, outputs.size())\n",
    "                    #print(\"model labels: \", labels.size())\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # torch.max outputs the maximum value, and its index\n",
    "                    # Since the input is batched, we take the max along axis 1\n",
    "                    # (the meaningful outputs)\n",
    "                    #print(\"outputs: \", outputs)\n",
    "                    #preds = torch.max(outputs, 1)\n",
    "                    preds = (outputs > 0).type(torch.float64)\n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    #print(\"new preds: \", preds)\n",
    "                    # backprop + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                #print(\"loss: \", loss.item())\n",
    "                #print(\"inputs: \", inputs.size(0), inputs.size())\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #print(\"running loss: \", running_loss)\n",
    "                #print(\"predictions: \", preds, preds.size())\n",
    "                #print(\"Labels: \", labels.data, labels.data.size())\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            #is the accuracy calculated correctly?\n",
    "            print(\"running_corrects: \", running_corrects.double(), running_corrects.size())\n",
    "            print(\"dataloaders len: \", len(dataloaders[phase].dataset)) \n",
    "            #maybe dataloaders length * number of classes? Model must predict for all classes\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), save_dir + \"/{}_best_weights_1.pt\".format(model_name))\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        print()\n",
    "        scheduler.step()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model):\n",
    "    # Get all the parameters\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "    # Use SGD\n",
    "    optimizer = optim.SGD(params_to_update, lr=0.01, momentum=0.9)\n",
    "    return optimizer\n",
    "\n",
    "def get_loss(num_classes,device):\n",
    "    # Create an instance of the loss function\n",
    "    #set weights to account for unbalanced data.\n",
    "    #In expectation every category class contributes the same to the loss\n",
    "    pos_weight = np.array([    0.025944895136267, 0.059170436277992,0.049543908183484,\n",
    "                            0.124453250588807,0.013364985606939,0.185904145949381,\n",
    "                            0.108022729821676,0.564067815619275,0.054011364910838])\n",
    "    pos_weight = torch.tensor(pos_weight,dtype=torch.float64) if num_classes == 9 \\\n",
    "    else torch.tensor([])\n",
    "    pos_weight = pos_weight.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    return criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet]\n",
    "# You can add your own, or modify these however you wish!\n",
    "model_name = \"resnet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "# Miniplaces has 100\n",
    "num_classes = 9# set to 9 or 14\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "# You should use a power of 2.\n",
    "batch_size = 64\n",
    "\n",
    "# Shuffle the input data?\n",
    "shuffle_datasets = True\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 10\n",
    "\n",
    "### IO\n",
    "# Path to a model file to use to start weights at\n",
    "#resume_from = \"/home/ubuntu/6.867-xray-project/weights/data_aug_vgg.pt\"\n",
    "resume_from = None\n",
    "\n",
    "# Directory to save weights to\n",
    "save_dir = \"weights\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# If True saves the weights for all epochs, else only saves the weight of best one\n",
    "save_all_epochs = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/ubuntu/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 22.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t cnn.conv1.weight\n",
      "\t cnn.bn1.weight\n",
      "\t cnn.bn1.bias\n",
      "\t cnn.layer1.0.conv1.weight\n",
      "\t cnn.layer1.0.bn1.weight\n",
      "\t cnn.layer1.0.bn1.bias\n",
      "\t cnn.layer1.0.conv2.weight\n",
      "\t cnn.layer1.0.bn2.weight\n",
      "\t cnn.layer1.0.bn2.bias\n",
      "\t cnn.layer1.1.conv1.weight\n",
      "\t cnn.layer1.1.bn1.weight\n",
      "\t cnn.layer1.1.bn1.bias\n",
      "\t cnn.layer1.1.conv2.weight\n",
      "\t cnn.layer1.1.bn2.weight\n",
      "\t cnn.layer1.1.bn2.bias\n",
      "\t cnn.layer2.0.conv1.weight\n",
      "\t cnn.layer2.0.bn1.weight\n",
      "\t cnn.layer2.0.bn1.bias\n",
      "\t cnn.layer2.0.conv2.weight\n",
      "\t cnn.layer2.0.bn2.weight\n",
      "\t cnn.layer2.0.bn2.bias\n",
      "\t cnn.layer2.0.downsample.0.weight\n",
      "\t cnn.layer2.0.downsample.1.weight\n",
      "\t cnn.layer2.0.downsample.1.bias\n",
      "\t cnn.layer2.1.conv1.weight\n",
      "\t cnn.layer2.1.bn1.weight\n",
      "\t cnn.layer2.1.bn1.bias\n",
      "\t cnn.layer2.1.conv2.weight\n",
      "\t cnn.layer2.1.bn2.weight\n",
      "\t cnn.layer2.1.bn2.bias\n",
      "\t cnn.layer3.0.conv1.weight\n",
      "\t cnn.layer3.0.bn1.weight\n",
      "\t cnn.layer3.0.bn1.bias\n",
      "\t cnn.layer3.0.conv2.weight\n",
      "\t cnn.layer3.0.bn2.weight\n",
      "\t cnn.layer3.0.bn2.bias\n",
      "\t cnn.layer3.0.downsample.0.weight\n",
      "\t cnn.layer3.0.downsample.1.weight\n",
      "\t cnn.layer3.0.downsample.1.bias\n",
      "\t cnn.layer3.1.conv1.weight\n",
      "\t cnn.layer3.1.bn1.weight\n",
      "\t cnn.layer3.1.bn1.bias\n",
      "\t cnn.layer3.1.conv2.weight\n",
      "\t cnn.layer3.1.bn2.weight\n",
      "\t cnn.layer3.1.bn2.bias\n",
      "\t cnn.layer4.0.conv1.weight\n",
      "\t cnn.layer4.0.bn1.weight\n",
      "\t cnn.layer4.0.bn1.bias\n",
      "\t cnn.layer4.0.conv2.weight\n",
      "\t cnn.layer4.0.bn2.weight\n",
      "\t cnn.layer4.0.bn2.bias\n",
      "\t cnn.layer4.0.downsample.0.weight\n",
      "\t cnn.layer4.0.downsample.1.weight\n",
      "\t cnn.layer4.0.downsample.1.bias\n",
      "\t cnn.layer4.1.conv1.weight\n",
      "\t cnn.layer4.1.bn1.weight\n",
      "\t cnn.layer4.1.bn1.bias\n",
      "\t cnn.layer4.1.conv2.weight\n",
      "\t cnn.layer4.1.bn2.weight\n",
      "\t cnn.layer4.1.bn2.bias\n",
      "\t cnn.fc.weight\n",
      "\t cnn.fc.bias\n",
      "\t fc1.weight\n",
      "\t fc1.bias\n",
      "\t fc2.weight\n",
      "\t fc2.bias\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349fb2ed3fc5403b8cbe78a9ffed897d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1005), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running_corrects:  tensor(504906., device='cuda:0', dtype=torch.float64) torch.Size([])\n",
      "dataloaders len:  64306\n",
      "train Loss: 0.1035 Acc: 7.8516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc421db7dde84b46b1d350a1c15ecf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=335), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running_corrects:  tensor(172010., device='cuda:0', dtype=torch.float64) torch.Size([])\n",
      "dataloaders len:  21392\n",
      "val Loss: 0.0878 Acc: 8.0409\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624753747d054ac0acffcc0bb61d4ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1005), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running_corrects:  tensor(515634., device='cuda:0', dtype=torch.float64) torch.Size([])\n",
      "dataloaders len:  64306\n",
      "train Loss: 0.0883 Acc: 8.0184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2d74d05fab40a592928fda915628a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=335), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running_corrects:  tensor(172429., device='cuda:0', dtype=torch.float64) torch.Size([])\n",
      "dataloaders len:  21392\n",
      "val Loss: 0.0856 Acc: 8.0604\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0236cb6bda4d2c9aa4c1522afbe71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1005), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running_corrects:  tensor(516985., device='cuda:0', dtype=torch.float64) torch.Size([])\n",
      "dataloaders len:  64306\n",
      "train Loss: 0.0869 Acc: 8.0395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5523557d674242901cdf5e38748e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=335), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "\n",
    "model = Chest_Disease_Net(cnn_model_name = model_name, num_classes = num_classes, resume_from = resume_from)\n",
    "input_size = model.input_size\n",
    "dataloaders = get_dataloaders(input_size, batch_size, num_classes, shuffle_datasets)\n",
    "criterion = get_loss(num_classes=num_classes,device=device)\n",
    "\n",
    "# Move the model to the gpu if needed\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = make_optimizer(model)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,10],gamma=0.1)\n",
    "# Train the model!\n",
    "trained_model, validation_history = train_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer,\n",
    "            scheduler=scheduler, model_name=model_name, save_dir=save_dir, save_all_epochs=save_all_epochs, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
